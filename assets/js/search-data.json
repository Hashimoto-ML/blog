{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "Import Package . install . !pip install pytorch-lightning !pip install wandb !pip install omegaconf . Collecting pytorch-lightning Downloading pytorch_lightning-1.4.1-py3-none-any.whl (915 kB) |████████████████████████████████| 915 kB 7.7 MB/s Requirement already satisfied: numpy&gt;=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5) Collecting torchmetrics&gt;=0.4.0 Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB) |████████████████████████████████| 234 kB 52.5 MB/s Collecting PyYAML&gt;=5.1 Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB) |████████████████████████████████| 636 kB 48.3 MB/s Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.7.4.3) Collecting pyDeprecate==0.3.1 Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB) Collecting fsspec[http]!=2021.06.0,&gt;=2021.05.0 Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB) |████████████████████████████████| 118 kB 53.0 MB/s Requirement already satisfied: torch&gt;=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.9.0+cu102) Requirement already satisfied: packaging&gt;=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.0) Requirement already satisfied: tqdm&gt;=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1) Collecting future&gt;=0.17.1 Downloading future-0.18.2.tar.gz (829 kB) |████████████████████████████████| 829 kB 43.3 MB/s Collecting tensorboard!=2.5.0,&gt;=2.2.0 Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB) |████████████████████████████████| 10.6 MB 21.6 MB/s Collecting aiohttp Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB) |████████████████████████████████| 1.3 MB 56.5 MB/s Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (2.23.0) Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;=17.0-&gt;pytorch-lightning) (2.4.7) Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (0.12.0) Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (3.3.4) Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (0.36.2) Requirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (1.32.1) Requirement already satisfied: grpcio&gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (1.34.1) Requirement already satisfied: protobuf&gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (3.17.3) Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (57.2.0) Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (1.8.0) Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (0.4.4) Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (1.15.0) Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (1.0.1) Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (4.7.2) Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (4.2.2) Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (0.2.8) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (1.3.0) Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown&gt;=2.6.8-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (4.6.1) Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (0.4.8) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (2021.5.30) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (1.24.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (3.0.4) Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (3.1.1) Collecting yarl&lt;2.0,&gt;=1.0 Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB) |████████████████████████████████| 294 kB 59.9 MB/s Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (21.2.0) Collecting async-timeout&lt;4.0,&gt;=3.0 Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB) Collecting multidict&lt;7.0,&gt;=4.5 Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB) |████████████████████████████████| 142 kB 69.5 MB/s Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;markdown&gt;=2.6.8-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning) (3.5.0) Building wheels for collected packages: future Building wheel for future (setup.py) ... done Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=9e35fce6cc643b257305a65481c279b3130db36146243ac21bb7e841c27781ea Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0 Successfully built future Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, torchmetrics, tensorboard, PyYAML, pyDeprecate, future, pytorch-lightning Attempting uninstall: tensorboard Found existing installation: tensorboard 2.5.0 Uninstalling tensorboard-2.5.0: Successfully uninstalled tensorboard-2.5.0 Attempting uninstall: PyYAML Found existing installation: PyYAML 3.13 Uninstalling PyYAML-3.13: Successfully uninstalled PyYAML-3.13 Attempting uninstall: future Found existing installation: future 0.16.0 Uninstalling future-0.16.0: Successfully uninstalled future-0.16.0 ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.4.1 which is incompatible. Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.7.0 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.1 pytorch-lightning-1.4.1 tensorboard-2.4.1 torchmetrics-0.4.1 yarl-1.6.3 Collecting wandb Downloading wandb-0.11.2-py2.py3-none-any.whl (1.8 MB) |████████████████████████████████| 1.8 MB 6.9 MB/s Collecting shortuuid&gt;=0.5.0 Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB) Collecting configparser&gt;=3.8.1 Downloading configparser-5.0.2-py3-none-any.whl (19 kB) Requirement already satisfied: psutil&gt;=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8) Collecting GitPython&gt;=1.0.0 Downloading GitPython-3.1.18-py3-none-any.whl (170 kB) |████████████████████████████████| 170 kB 56.5 MB/s Requirement already satisfied: six&gt;=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0) Collecting pathtools Downloading pathtools-0.1.2.tar.gz (11 kB) Collecting subprocess32&gt;=3.5.3 Downloading subprocess32-3.5.4.tar.gz (97 kB) |████████████████████████████████| 97 kB 8.0 MB/s Collecting docker-pycreds&gt;=0.4.0 Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB) Collecting sentry-sdk&gt;=1.0.0 Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB) |████████████████████████████████| 133 kB 62.1 MB/s Requirement already satisfied: requests&lt;3,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0) Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.1) Collecting urllib3&gt;=1.26.5 Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB) |████████████████████████████████| 138 kB 23.0 MB/s Requirement already satisfied: Click!=8.0.0,&gt;=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2) Requirement already satisfied: protobuf&gt;=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3) Requirement already satisfied: promise&lt;3,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3) Requirement already satisfied: python-dateutil&gt;=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1) Requirement already satisfied: typing-extensions&gt;=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython&gt;=1.0.0-&gt;wandb) (3.7.4.3) Collecting gitdb&lt;5,&gt;=4.0.1 Downloading gitdb-4.0.7-py3-none-any.whl (63 kB) |████████████████████████████████| 63 kB 2.3 MB/s Collecting smmap&lt;5,&gt;=3.0.1 Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2021.5.30) Collecting requests&lt;3,&gt;=2.0.0 Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB) |████████████████████████████████| 62 kB 1.1 MB/s Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2.0.2) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2.10) Building wheels for collected packages: subprocess32, pathtools Building wheel for subprocess32 (setup.py) ... done Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=cdacf7590ae1dc6cb010bb34e877b6554c33597c0a98ac21ef2aeecfe00a141c Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a Building wheel for pathtools (setup.py) ... done Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=85801e6e5d42de5cf11fe1806983ce6f59c64c0cc66857289cb766733976f035 Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2 Successfully built subprocess32 pathtools Installing collected packages: smmap, urllib3, gitdb, subprocess32, shortuuid, sentry-sdk, requests, pathtools, GitPython, docker-pycreds, configparser, wandb Attempting uninstall: urllib3 Found existing installation: urllib3 1.24.3 Uninstalling urllib3-1.24.3: Successfully uninstalled urllib3-1.24.3 Attempting uninstall: requests Found existing installation: requests 2.23.0 Uninstalling requests-2.23.0: Successfully uninstalled requests-2.23.0 ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible. datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible. Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 requests-2.26.0 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 urllib3-1.26.6 wandb-0.11.2 Collecting omegaconf Downloading omegaconf-2.1.0-py3-none-any.whl (74 kB) |████████████████████████████████| 74 kB 2.9 MB/s Requirement already satisfied: PyYAML&gt;=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf) (5.4.1) Collecting antlr4-python3-runtime==4.8 Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB) |████████████████████████████████| 112 kB 59.9 MB/s Building wheels for collected packages: antlr4-python3-runtime Building wheel for antlr4-python3-runtime (setup.py) ... done Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=82f0e648dfc106b62d173aea7f4510e9cd499d666543fdcca1997968041bca49 Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c Successfully built antlr4-python3-runtime Installing collected packages: antlr4-python3-runtime, omegaconf Successfully installed antlr4-python3-runtime-4.8 omegaconf-2.1.0 . import . import wandb import numpy as np import torch import torchvision import pytorch_lightning as pl from torch import nn from torch import optim from torch.nn import functional as F from torch.utils.data import DataLoader from torchvision.datasets import MNIST from torchvision import transforms from omegaconf import OmegaConf from datetime import datetime . Set Params . params = OmegaConf.create({ &#39;dataset&#39;: { &#39;batch_size&#39;: 256 }, &#39;lt&#39; : { &#39;latent_dim&#39;: 100, &#39;lr&#39;: 0.0002, &#39;b1&#39;: 0.5, &#39;b2&#39;: 0.999, }, &#39;trainer&#39;: { &#39;gpus&#39; : -1, &#39;max_epochs&#39;: 3, } }) . Data Module . class MNIST_DataModule(pl.LightningDataModule): def __init__(self, data_dir=&#39;./&#39;, batch_size=128): super().__init__() self.data_dir = data_dir self.batch_size = batch_size self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) self.dims = (1, 28, 28) self.num_classes = 10 def prepare_data(self): MNIST(self.data_dir, train=True, download=True) MNIST(self.data_dir, train=False, download=True) def setup(self, stage=None): self.train_dataset = MNIST(self.data_dir, train=True, transform=self.transform) self.val_dataset = MNIST(self.data_dir, train=False, transform=self.transform) def train_dataloader(self): return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True) def val_dataloader(self): return DataLoader(self.val_dataset, batch_size=144, shuffle=False) . LT Module . Component . class Generator(nn.Module): def __init__(self, latent_dim, x_shape): super().__init__() self.x_shape = x_shape def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.net = nn.Sequential( *block(latent_dim, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(x_shape))), nn.Tanh(), ) def forward(self, z): img = self.net(z) img = img.view(img.size(0), *self.x_shape) return img . NameError Traceback (most recent call last) &lt;ipython-input-1-e16aa7aeedb1&gt; in &lt;module&gt;() -&gt; 1 class Generator(nn.Module): 2 3 def __init__(self, latent_dim, x_shape): 4 super().__init__() 5 self.x_shape = x_shape NameError: name &#39;nn&#39; is not defined . class Discriminator(nn.Module): def __init__(self, x_shape): super().__init__() self.model = nn.Sequential( nn.Linear(int(np.prod(x_shape)), 512), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace=True), nn.Linear(256, 1), nn.Sigmoid(), ) def forward(self, x): x = x.view(x.size(0), -1) validity = self.model(x) return validity . Module . class GAN_Module(pl.LightningModule): def __init__(self, data_shape, params): super().__init__() self.save_hyperparameters() self.hp = params.lt self.generator = Generator(latent_dim=self.hp.latent_dim, x_shape=data_shape) self.discriminator = Discriminator(x_shape=data_shape) self.validation_z = torch.randn(25, self.hp.latent_dim) def forward(self, z): return self.generator(z) def adversarial_loss(self, y_hat, y): return F.binary_cross_entropy(y_hat, y) def training_step(self, batch, batch_idx, optimizer_idx): imgs, _ = batch # sample noise z = torch.randn(imgs.shape[0], self.hp.latent_dim).type_as(imgs) # train generator if optimizer_idx == 0: # generate images self.generated_imgs = self(z) # required result ( discreminator misjudge ) valid = torch.ones(imgs.size(0), 1).type_as(imgs) # generator loss g_loss = self.adversarial_loss(self.discriminator(self(z)), valid) self.log(&#39;train/g_loss&#39;, g_loss) return {&#39;loss&#39;: g_loss} # train discriminator if optimizer_idx == 1: # real image valid = torch.ones(imgs.size(0), 1).type_as(imgs) real_loss = self.adversarial_loss(self.discriminator(imgs), valid) # generated image fake = torch.zeros(imgs.size(0), 1).type_as(imgs) fake_loss = self.adversarial_loss(self.discriminator(self(z).detach()), fake) # discriminator loss d_loss = (real_loss + fake_loss) / 2 self.log(&#39;train/d_loss&#39;, d_loss) return {&#39;loss&#39;: d_loss} def configure_optimizers(self): opt_g = torch.optim.Adam(self.generator.parameters(), lr=self.hp.lr, betas=(self.hp.b1, self.hp.b2)) opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=self.hp.lr, betas=(self.hp.b1, self.hp.b2)) return [opt_g, opt_d], [] def on_epoch_end(self): # log sampled images sample_imgs = self.generated_imgs[:25] grid = torchvision.utils.make_grid(sample_imgs, nrow=5) self.log(&#39;test_generated_images&#39;, wandb.Image(grid)) z = self.validation_z.type_as(self.generator.net[0].weight) sample_imgs = self(z) grid = torchvision.utils.make_grid(sample_imgs, nrow=5) self.log(&#39;val_generated_images&#39;, wandb.Image(grid)) . RUN . wandb.login() wandb_logger = pl.loggers.WandbLogger(name = datetime.now().strftime(&#39;%y%m%d-%H%M%S&#39;), project = &#39;Basic GAN&#39;, tags=[&#39;gan&#39;, &#39;notebook&#39;]) # データセット dm = MNIST_DataModule(**params.dataset) # モデル model = GAN_Module(dm.size(), params) # 学習設定 trainer = pl.Trainer(logger=wandb_logger, deterministic=True, **params.trainer) # 学習実行 trainer.fit(model, dm) # logger を閉じる wandb.finish() . GPU available: True, used: True TPU available: False, using: 0 TPU cores /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:99: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping val loop rank_zero_warn(f&#39;you passed in a {loader_name} but have no {step_name}. Skipping {stage} loop&#39;) . Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz Failed to download (trying next): HTTP Error 503: Service Unavailable Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz . /usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.) return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s) LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw . Tracking run with wandb version 0.10.33 Syncing run 210714-040728 to Weights &amp; Biases (Documentation). Project page: https://wandb.ai/hashimoto/Basic%20GAN Run page: https://wandb.ai/hashimoto/Basic%20GAN/runs/22s87fxq Run data is saved locally in /content/wandb/run-20210714_041236-22s87fxq | Name | Type | Params 0 | generator | Generator | 1.5 M 1 | discriminator | Discriminator | 533 K 2.0 M Trainable params 0 Non-trainable params 2.0 M Total params 8.174 Total estimated model params size (MB) . . Waiting for W&amp;B process to finish, PID 441Program ended successfully. Find user logs for this run at: /content/wandb/run-20210714_041236-22s87fxq/logs/debug.log Find internal logs for this run at: /content/wandb/run-20210714_041236-22s87fxq/logs/debug-internal.log Run summary: . train/g_loss | 1.12359 | . train/d_loss | 0.54438 | . epoch | 2 | . trainer/global_step | 704 | . _runtime | 33 | . _timestamp | 1626235989 | . _step | 16 | . Run history: . train/g_loss | ▁▁▂▃▃▅▃▃▃▄▄█▁▄ | . train/d_loss | ▅█▆▅▃▄▁▄▃▃▂▂▆▃ | . epoch | ▁▁▁▁▁▅▅▅▅▅▅██████ | . trainer/global_step | ▁▂▂▃▃▃▄▄▅▅▅▆▆▇▇██ | . _runtime | ▁▁▂▃▃▃▄▄▅▅▅▆▆▇▇██ | . _timestamp | ▁▁▂▃▃▃▄▄▅▅▅▆▆▇▇██ | . _step | ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██ | . Synced 5 W&amp;B file(s), 6 media file(s), 2 artifact file(s) and 2 other file(s) Synced 210714-040728: https://wandb.ai/hashimoto/Basic%20GAN/runs/22s87fxq",
            "url": "https://thash-ebm.github.io/blog/jupyter/2021/08/06/GAN.html",
            "relUrl": "/jupyter/2021/08/06/GAN.html",
            "date": " • Aug 6, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://thash-ebm.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://thash-ebm.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://thash-ebm.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://thash-ebm.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}